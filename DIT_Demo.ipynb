{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "DIT Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KYwlAE4UetKO",
        "QXUEak-Oe2jS",
        "SLWldYlgQIHv",
        "dRWcLJItGObX",
        "3yJYE3crQVDB",
        "0JHUuogPijyb",
        "lJ7Aw2wDG2bF"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyWOlqpGh1-i",
        "colab_type": "text"
      },
      "source": [
        "# Resources\n",
        "\n",
        "**Tools**  \n",
        "[Folium Bubble Map](https://python-graph-gallery.com/313-bubble-map-with-folium/)  \n",
        "[Individual Choropleth Popups](http://www.mattgoldwasser.com/posts/choroplot/)  \n",
        "[TimeSliderChoropleth Example](https://github.com/python-visualization/folium/blob/master/examples/TimeSliderChoropleth.ipynb)  \n",
        "[Time Series Folium Example](https://geohackweek.github.io/ghw2018_web_portal_inlandwater_co2/InteractiveTimeSeries.html)  \n",
        "\n",
        "\n",
        "**Dataset**  \n",
        "[Annual GDP Growth %](https://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG)  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQQ6ll_s1HK1",
        "colab_type": "text"
      },
      "source": [
        "# Imports & Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-30T08:07:52.506461Z",
          "start_time": "2020-01-30T08:07:44.687918Z"
        },
        "id": "SOG9oQCEh1-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "355c2afd-4397-4e11-a50d-46324e9fc23d"
      },
      "source": [
        "!pip install geopandas\n",
        "!pip install ipyleaflet\n",
        "!pip install beautifulsoup4\n",
        "!pip install geopy\n",
        "!pip install googlemaps\n",
        "!pip install zipcodes\n",
        "!pip install addfips #Finds fips code from county and state name\n",
        "\n",
        "# Import Analysis Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter,defaultdict\n",
        "import os\n",
        "\n",
        "# Other Tools\n",
        "from tqdm import trange,tqdm\n",
        "from geopy.geocoders import Nominatim # find latitude and longitude by county names for folium mapping\n",
        "import googlemaps # Geolocation finder\n",
        "from datetime import datetime\n",
        "import zipcodes\n",
        "import addfips\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Visualization\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.font_manager\n",
        "color_palette_list = ['#009ACD', '#ADD8E6', '#63D1F4', '#0EBFE9','#C1F0F6', '#0099CC']\n",
        "import geopandas as gpd\n",
        "from ipyleaflet import Map, GeoData, basemaps, LayersControl\n",
        "%matplotlib inline\n",
        "import folium\n",
        "from folium.plugins import TimeSliderChoropleth\n",
        "\n",
        "# Jupyter Notebook & Pandas Set\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
        "pd.set_option('display.max_columns',100)\n",
        "\n",
        "# WebScraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# ETC\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up connectivity with gdrive with colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a4/e66aafbefcbb717813bf3a355c8c4fc3ed04ea1dd7feb2920f2f4f868921/geopandas-0.8.1-py2.py3-none-any.whl (962kB)\n",
            "\u001b[K     |████████████████████████████████| 972kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.0.5)\n",
            "Collecting fiona\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/52/4ea26c566c401b2a7337549a42141a6552cf71744d970114e59126b05ed6/Fiona-1.8.15-cp36-cp36m-manylinux1_x86_64.whl (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8MB 304kB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.1)\n",
            "Collecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c3/071e080230ac4b6c64f1a2e2f9161c9737a2bc7b683d2c90b024825000c0/pyproj-2.6.1.post1-cp36-cp36m-manylinux2010_x86_64.whl (10.9MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9MB 45.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.15.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/be/30a58b4b0733850280d01f8bd132591b4668ed5c7046761098d665ac2174/cligj-0.5.0-py3-none-any.whl\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (20.1.0)\n",
            "Installing collected packages: munch, cligj, click-plugins, fiona, pyproj, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.5.0 fiona-1.8.15 geopandas-0.8.1 munch-2.5.0 pyproj-2.6.1.post1\n",
            "Collecting ipyleaflet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/9d/f411b8a9522f1710f278c60b2cd8d26817d8c64b7568de95f9437db6caf0/ipyleaflet-0.13.3-py2.py3-none-any.whl (5.1MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1MB 2.7MB/s \n",
            "\u001b[?25hCollecting traittypes<3,>=0.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/d1/8d5bd662703cc1764d986f6908a608777305946fa634d34c470cd4a1e729/traittypes-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipywidgets<8,>=7.5.0 in /usr/local/lib/python3.6/dist-packages (from ipyleaflet) (7.5.1)\n",
            "Requirement already satisfied: branca<0.5,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from ipyleaflet) (0.4.1)\n",
            "Requirement already satisfied: traitlets>=4.2.2 in /usr/local/lib/python3.6/dist-packages (from traittypes<3,>=0.2.1->ipyleaflet) (4.3.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets<8,>=7.5.0->ipyleaflet) (4.10.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets<8,>=7.5.0->ipyleaflet) (3.5.1)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets<8,>=7.5.0->ipyleaflet) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets<8,>=7.5.0->ipyleaflet) (5.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from branca<0.5,>=0.3.1->ipyleaflet) (2.11.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.2->traittypes<3,>=0.2.1->ipyleaflet) (4.4.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.2->traittypes<3,>=0.2.1->ipyleaflet) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.2->traittypes<3,>=0.2.1->ipyleaflet) (1.15.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.5.0->ipyleaflet) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.5.0->ipyleaflet) (5.1.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (5.3.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.5.0->ipyleaflet) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.5.0->ipyleaflet) (49.6.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.5.0->ipyleaflet) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.5.0->ipyleaflet) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.5.0->ipyleaflet) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.5.0->ipyleaflet) (2.1.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets<8,>=7.5.0->ipyleaflet) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets<8,>=7.5.0->ipyleaflet) (4.6.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->branca<0.5,>=0.3.1->ipyleaflet) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7.5.0->ipyleaflet) (2.8.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7.5.0->ipyleaflet) (19.0.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (0.8.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (5.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.5.0->ipyleaflet) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets<8,>=7.5.0->ipyleaflet) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (3.1.5)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (1.4.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (20.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.5.0->ipyleaflet) (2.4.7)\n",
            "Installing collected packages: traittypes, ipyleaflet\n",
            "Successfully installed ipyleaflet-0.13.3 traittypes-0.2.1\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.6/dist-packages (1.17.0)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.6/dist-packages (from geopy) (1.50)\n",
            "Collecting googlemaps\n",
            "  Downloading https://files.pythonhosted.org/packages/00/fa/508909813a3f0ff969d341695ee0b90cb0e954b4b536f17f15cc19b5c304/googlemaps-4.4.2.tar.gz\n",
            "Requirement already satisfied: requests<3.0,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from googlemaps) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (1.24.3)\n",
            "Building wheels for collected packages: googlemaps\n",
            "  Building wheel for googlemaps (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googlemaps: filename=googlemaps-4.4.2-cp36-none-any.whl size=37858 sha256=af876ceb90cba29b270ae300d60d5c7db5f1b168bb1feea535e8ed961704cf58\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/21/41/0c84572e21d52bb322f6c299f38ac7cd8ad6d4d6ce23dc3631\n",
            "Successfully built googlemaps\n",
            "Installing collected packages: googlemaps\n",
            "Successfully installed googlemaps-4.4.2\n",
            "Collecting zipcodes\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/33/da326d64915c1ac7ca8c3232b004ff6c8c60a326012a970199455c437f31/zipcodes-1.1.2-py2.py3-none-any.whl (717kB)\n",
            "\u001b[K     |████████████████████████████████| 727kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: zipcodes\n",
            "Successfully installed zipcodes-1.1.2\n",
            "Collecting addfips\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/72/4f76cc094b3c8c302d5eddc6d961f29ca610a07ba321e919badb293422f6/addfips-0.2.2-py2.py3-none-any.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.1MB/s \n",
            "\u001b[?25hInstalling collected packages: addfips\n",
            "Successfully installed addfips-0.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYwlAE4UetKO",
        "colab_type": "text"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoJSDZX3ex8u",
        "colab_type": "text"
      },
      "source": [
        "## Folium Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWEpLp86etX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(folium.FeatureGroup)\n",
        "def folium_census(mapobj,gdf,key,color,show=False):\n",
        "  # Prep data\n",
        "  folium_gdf = gdf\n",
        "  folium_gdf.crs = {'init' :'epsg:4326'}\n",
        "  json_folium = folium_gdf.to_crs(epsg='4326').to_json()\n",
        "\n",
        "  folium.Choropleth(\n",
        "  geo_data=json_folium,\n",
        "  name=\"COVID-19 Confirmed Cases Total\",\n",
        "  data=folium_gdf,\n",
        "  columns=['GEOID', key],\n",
        "  key_on='properties.GEOID',\n",
        "  fill_color=color, # All colors : http://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3\n",
        "  fill_opacity=1,\n",
        "  line_opacity=3,\n",
        "  legend_name=key,\n",
        "  show=show\n",
        "  ).add_to(mapobj)\n",
        "\n",
        "  return mapobj\n",
        "\n",
        "def folium_marker(mapobj,popup_msg,icon_color,icon_type,longitude,latitude):\n",
        "  # https://getbootstrap.com/docs/3.3/components/#glyphicons-glyphs for built-in available icon types\n",
        "  folium.Marker(\n",
        "    location=[latitude,longitude],\n",
        "    popup=popup_msg,\n",
        "    icon=folium.Icon(color=icon_color,icon=icon_type)\n",
        "  ).add_to(mapobj)\n",
        "  return mapobj\n",
        "\n",
        "\n",
        "def folium_marker_cluster(mapobj,df,cluster_name,popup_msg,icon_color,icon_type,show=False):\n",
        "\n",
        "  from folium.plugins import MarkerCluster\n",
        "  icon_create_function = \"\"\"\n",
        "      function(cluster) {\n",
        "      var childCount = cluster.getChildCount(); \n",
        "      var c = ' marker-cluster-';\n",
        "\n",
        "      if (childCount < 200) {\n",
        "          c += 'large';\n",
        "      } else if (childCount < 500) {\n",
        "          c += 'medium';\n",
        "      } else {\n",
        "          c += 'small';\n",
        "      }\n",
        "\n",
        "      return new L.DivIcon({ html: '<div><span>' + childCount + '</span></div>', className: 'marker-cluster' + c, iconSize: new L.Point(40, 40) });\n",
        "      }\n",
        "      \"\"\"\n",
        "  mc = MarkerCluster(name=cluster_name,icon_create_function=icon_create_function,show=show)\n",
        "  #mc = MarkerCluster(name=cluster_name,show=False)\n",
        "  mc.add_to(mapobj)\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    mc.add_child(folium.Marker(location = [df['Latitude'].iloc[i],df['Longitude'].iloc[i]],\n",
        "                  popup=popup_msg,\n",
        "                  icon=folium.Icon(color=icon_color,icon=icon_type)\n",
        "                  ))\n",
        "  return mapobj\n",
        "\n",
        "def folium_feature_group(mapobj,df,cluster_name,icon_color,icon_type,show=False):\n",
        "  '''\n",
        "  Below blocked out code lets urls to be included, couldn't get it to work yet.\n",
        "  '''\n",
        "  # def get_frame(url,width,height):\n",
        "  #   html = \"\"\" \n",
        "  #           <!doctype html>\n",
        "  #       <html>\n",
        "  #       <iframe id=\"myIFrame\" width=\"{}\" height=\"{}\" src={}\"\"\".format(width,height,url) + \"\"\" frameborder=\"0\"></iframe>\n",
        "  #       <script type=\"text/javascript\">\n",
        "  #       var resizeIFrame = function(event) {\n",
        "  #           var loc = document.location;\n",
        "  #           if (event.origin != loc.protocol + '//' + loc.host) return;\n",
        "\n",
        "  #           var myIFrame = document.getElementById('myIFrame');\n",
        "  #           if (myIFrame) {\n",
        "  #               myIFrame.style.height = event.data.h + \"px\";\n",
        "  #               myIFrame.style.width  = event.data.w + \"px\";\n",
        "  #           }\n",
        "  #       };\n",
        "  #       if (window.addEventListener) {\n",
        "  #           window.addEventListener(\"message\", resizeIFrame, false);\n",
        "  #       } else if (window.attachEvent) {\n",
        "  #           window.attachEvent(\"onmessage\", resizeIFrame);\n",
        "  #       }\n",
        "  #       </script>\n",
        "  #       </html>\"\"\"\n",
        "  #   return html\n",
        "  #   popup = get_frame('https://stackoverflow.com/questions/29535715/python-with-folium-how-can-i-embed-a-webpage-in-the-popup',\n",
        "  #             500,\n",
        "  #             500)\n",
        "\n",
        "\n",
        "\n",
        "  fg = folium.FeatureGroup(name=cluster_name,show=show)\n",
        "\n",
        "  print(\"Populating Annual GDP Growth graph per country...\")\n",
        "  time.sleep(1)\n",
        "  for i in trange(len(df)):\n",
        "\n",
        "    import base64\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    resolution, width, height = 75, 15, 4\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(width, height))\n",
        "    ax.plot( gdp_growth[gdp_growth['COUNTRY']==df['country'].iloc[i]]['year'], gdp_growth[gdp_growth['COUNTRY']==df['country'].iloc[i]]['value'])\n",
        "    plt.xticks(rotation=80)\n",
        "    plt.ylabel('GDP Growth %')\n",
        "    ax.set_title(df['country'].iloc[i])\n",
        "    plt.close(fig)\n",
        "    png = 'viz.png'\n",
        "\n",
        "    fig.savefig(png, dpi=resolution)\n",
        "\n",
        "    encoded = base64.b64encode(open(png, 'rb').read())\n",
        "\n",
        "    from folium import IFrame\n",
        "\n",
        "    html = '<img src=\"data:image/png;base64,{}\">'.format\n",
        "    iframe = IFrame(html(encoded.decode('UTF-8')), width=(width*resolution)+20, height=(height*resolution)+20)\n",
        "    popup = folium.Popup(iframe, max_width=2650)\n",
        "\n",
        "\n",
        "\n",
        "    fg.add_child(folium.Marker(location = [df['latitude'].iloc[i],df['longitude'].iloc[i]],\n",
        "                  popup=popup,\n",
        "                  icon=folium.Icon(color=icon_color,icon=icon_type)\n",
        "                  ))\n",
        "    \n",
        "  fg.add_to(mapobj)\n",
        "  return mapobj\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXUEak-Oe2jS",
        "colab_type": "text"
      },
      "source": [
        "## API Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZeCRWJue2tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing required modules \n",
        "def google_places_search(category,search_sentence,search_limit):\n",
        "  import requests, json \n",
        "  category_list = []\n",
        "  name_of_place_list = []\n",
        "  address_list = []\n",
        "  longitude_list = []\n",
        "  latitude_list = []\n",
        "\n",
        "  api_key = 'AIzaSyBYs956hhLw4fbe0dchr-WJGyZ5sOgAO5E'\n",
        "  url = \"https://maps.googleapis.com/maps/api/place/textsearch/json?\"\n",
        "    \n",
        "    \n",
        "  r = requests.get(url + 'query=' + search_sentence +\n",
        "                          '&key=' + api_key) \n",
        "  x = r.json()   \n",
        "  y = x['results'] \n",
        "\n",
        "  # keep looping upto length of y \n",
        "\n",
        "  for i in range(len(y)):\n",
        "    if y[i]['formatted_address'].split(',')[-2].split()[-2] == search_limit:\n",
        "      category_list.append(category)\n",
        "      name_of_place_list.append(y[i]['name'])\n",
        "      address_list.append(y[i]['formatted_address'])\n",
        "      longitude_list.append(y[i]['geometry']['location']['lng'])\n",
        "      latitude_list.append(y[i]['geometry']['location']['lat'])\n",
        "  return pd.DataFrame({'Category':category_list,\n",
        "                       'Place Name':name_of_place_list,\n",
        "                       'Address':address_list,\n",
        "                       'Longitude':longitude_list,\n",
        "                       'Latitude':latitude_list\n",
        "                       })\n",
        "\n",
        "def geolocation_finder(name_list,county_list=None):\n",
        "  gmaps = googlemaps.Client(key='AIzaSyBYs956hhLw4fbe0dchr-WJGyZ5sOgAO5E')\n",
        "  facilities = []\n",
        "  longitude = []\n",
        "  latitude = []\n",
        "  zipcode = []\n",
        "  county = []\n",
        "  state = []\n",
        "  if county_list!=None:\n",
        "    for ix,name in enumerate(tqdm(name_list)):\n",
        "      facility_name = name\n",
        "      facility_county = county_list[ix]\n",
        "      geocode_result = gmaps.geocode(name)\n",
        "      if len(geocode_result)!=0:          \n",
        "        facilities.append(name)\n",
        "        latitude.append(geocode_result[0]['geometry']['location']['lat'])\n",
        "        longitude.append(geocode_result[0]['geometry']['location']['lng'])\n",
        "        returned_zipcode = geocode_result[0]['formatted_address'].split(' ')[-2].split(',')[0]\n",
        "        # Sometimes Zip code is not found. In this case add \"Zip Not Found\"\n",
        "        if len(returned_zipcode)>4:\n",
        "          zipcode.append(returned_zipcode)\n",
        "          county.append(zipcodes.matching(str(geocode_result[0]['formatted_address'].split(' ')[-2].split(',')[0]))[0]['county'])\n",
        "          state.append(geocode_result[0]['formatted_address'].split(' ')[-3])\n",
        "        else:\n",
        "          zipcode.append('Zip Not Found')\n",
        "          county.append('Zip Not Found')\n",
        "          state.append('Zip Not Found')\n",
        "\n",
        "  else:\n",
        "     for ix,name in enumerate(tqdm(name_list)):\n",
        "      facility_name = name\n",
        "      geocode_result = gmaps.geocode(name)\n",
        "      if len(geocode_result)!=0:  \n",
        "        facilities.append(name)\n",
        "        latitude.append(geocode_result[0]['geometry']['location']['lat'])\n",
        "        longitude.append(geocode_result[0]['geometry']['location']['lng']) \n",
        "        returned_zipcode = geocode_result[0]['formatted_address'].split(' ')[-2].split(',')[0]\n",
        "        # Sometimes Zip code is not found. In this case add \"Zip Not Found\"\n",
        "        if len(returned_zipcode)>4:\n",
        "          zipcode.append(returned_zipcode)\n",
        "          county.append(zipcodes.matching(str(geocode_result[0]['formatted_address'].split(' ')[-2].split(',')[0]))[0]['county'])\n",
        "          state.append(geocode_result[0]['formatted_address'].split(' ')[-3])\n",
        "        else:\n",
        "          zipcode.append('Zip Not Found')\n",
        "          county.append('Zip Not Found')\n",
        "          state.append('Zip Not Found')\n",
        "  return pd.DataFrame({'Name':facilities,\n",
        "                       'Zipcode':zipcode,\n",
        "                       'County':county,\n",
        "                       'State':state,\n",
        "                       'Longitude':longitude,\n",
        "                       'Latitude':latitude\n",
        "                       })\n",
        " \n",
        "\n",
        "def google_places_search_custom(keyword,zipcode_list):\n",
        "  \n",
        "  df=pd.DataFrame({'Category':[],\t'Place Name':[],\t'Address':[]\t,'Longitude':[],\t'Latitude':[]})\n",
        "\n",
        "  for i in range(0,len(zipcode_list),10):\n",
        "    df = pd.concat([df,\n",
        "              google_places_search(keyword,keyword+\" in zipcode \"+str(zipcode_list[i]))\n",
        "              ])\n",
        "    df = df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3xYf3ZV1CvE",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLWldYlgQIHv",
        "colab_type": "text"
      },
      "source": [
        "### UK Imports Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpiVkeGD_yKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4867f46c-4229-4171-f409-e32c94159606"
      },
      "source": [
        "print(\"Importing balance of trade Data...\")\n",
        "\n",
        "uk_bot = pd.read_csv('gdrive/My Drive/PA Consulting/DIT EU Support/bot_with_tariffs_calcs.csv') \n",
        "\n",
        "# Create a new column with country abbreviations removed. ex) \"AE United Arab Emirates\" -> \"United Arab Emirates\" to merge it with shapefiles\n",
        "uk_bot['COUNTRY'] = uk_bot['COUNTRY'].apply( lambda x :  ' '.join(x.split()[1:]) )\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Importing balance of trade Data...\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qo2JneFD1FV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rename some countries' name to be able to merge with shapefiles\n",
        "\n",
        "uk_bot = uk_bot.replace({'COUNTRY' : \n",
        "                      dict.fromkeys(['Hong Kong', \n",
        "                                     'Macau'], \n",
        "                                     'China')})\n",
        "\n",
        "uk_bot = uk_bot.replace({'COUNTRY' : \n",
        "                      dict.fromkeys(['Vatican City'], \n",
        "                                     'Italy')})\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRWcLJItGObX",
        "colab_type": "text"
      },
      "source": [
        "### Import lon & lat data for each country for markers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCTXzDzGGN_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "country_markers = pd.read_csv('gdrive/My Drive/PA Consulting/DIT EU Support/countries_lat_lon.csv', encoding = \"ISO-8859-1\") \n",
        "country_markers = country_markers[country_markers['country']!='U.S. Minor Outlying Islands']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yngFR7HoN4d",
        "colab_type": "text"
      },
      "source": [
        "### Annual GDP Growth % data for marker's popup messages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7udMSEroNPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdp_growth = pd.read_csv('gdrive/My Drive/PA Consulting/DIT EU Support/gdp_annual_percentage.csv',skiprows=4)  #https://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG\n",
        "gdp_growth = gdp_growth.rename(columns={'Country Name': 'COUNTRY'})\n",
        "gdp_growth.drop(columns=['Country Code', 'Indicator Name', 'Indicator Code','Unnamed: 64'],inplace=True)\n",
        "\n",
        "# Stretch out the data\n",
        "gdp_growth = gdp_growth.melt(id_vars=['COUNTRY'], var_name='year')\n",
        "\n",
        "# Drop na and re order data by country and year\n",
        "gdp_growth.dropna(inplace=True)\n",
        "gdp_growth = gdp_growth.sort_values(by=['COUNTRY','year'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yJYE3crQVDB",
        "colab_type": "text"
      },
      "source": [
        "### Country Shape Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsOBtmY0V4Sg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5ed806a5-a113-49ff-b7bb-1637720a1d98"
      },
      "source": [
        "print(\"Loading country shape files for Folium...\")\n",
        "gdf_countries = gpd.GeoDataFrame.from_file('gdrive/My Drive/shapefiles/world countries/99bfd9e7-bb42-4728-87b5-07f8c8ac631c2020328-1-1vef4ev.lu5nk.shp') #https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_county_500k.zip <- All Counties in US\n",
        "gdf_countries = gdf_countries.rename(columns={'CNTRY_NAME': 'COUNTRY'})\n",
        "gdf_countries.drop(columns=['OBJECTID'],inplace=True)\n",
        "print(\"Done\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading country shape files for Folium...\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f699jkGi39TE",
        "colab_type": "text"
      },
      "source": [
        "### Data Inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tehY1OIH358D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Not all countries in import & export files exist in shape files, so those won't be displayed on Folium\n",
        "countries_in_shape_files = []\n",
        "countries_not_in_shape_files = []\n",
        "\n",
        "for country in list(set(uk_bot['COUNTRY'])):\n",
        "  if country not in list(set(uk_bot['COUNTRY']) & set(gdf_countries['COUNTRY'])):\n",
        "    countries_not_in_shape_files.append(country)\n",
        "  else:\n",
        "    countries_in_shape_files.append(country)\n",
        "countries_not_in_shape_files = sorted(countries_not_in_shape_files)\n",
        "countries_in_shape_files = sorted(countries_in_shape_files)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3uZfE-U5w0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unique commodities\n",
        "commodities = list(uk_bot['COMMODITY'].unique())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpychVppIl6w",
        "colab_type": "text"
      },
      "source": [
        "### Select subset of commodity from import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6PYxkWaIlgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "commodity = commodities[0]\n",
        "uk_bot_commodity1 = uk_bot[uk_bot['COMMODITY'] == commodity]\n",
        "\n",
        "# Drop unneeded columns\n",
        "uk_bot_commodity1.drop(columns=['DIRECTION','commodity_key'],inplace=True)\n",
        "\n",
        "# Stretch out the data\n",
        "uk_bot_commodity1 = uk_bot_commodity1.melt(id_vars=['COMMODITY', 'COUNTRY'], var_name='date')\n",
        "\n",
        "# Reformat date to actual datetime\n",
        "uk_bot_commodity1['date'] = uk_bot_commodity1['date'].apply(lambda x:datetime.strptime(x.split('_')[0],'%Y%b'))\n",
        "uk_bot_commodity1['date_sec'] = uk_bot_commodity1['date'].astype(int) / 10**9\n",
        "uk_bot_commodity1['date_sec'] = uk_bot_commodity1['date_sec'].astype(int).astype(str)\n",
        "\n",
        "# Reorder data by country and date\n",
        "uk_bot_commodity1 = uk_bot_commodity1.sort_values(by=['COUNTRY','date'])\n",
        "\n",
        "# Reset index\n",
        "uk_bot_commodity1.reset_index(inplace=True,drop=True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mZooQx9fnJ8",
        "colab_type": "text"
      },
      "source": [
        "### Merge data with shape files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMPC6kIn5759",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "03949e8a-dd1b-4a2c-d865-cea3f8f32697"
      },
      "source": [
        "print(\"Merging all data...\")\n",
        "\n",
        "gdf_commodity1 = uk_bot_commodity1.merge(gdf_countries, left_on='COUNTRY',right_on='COUNTRY')\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Merging all data...\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JHUuogPijyb",
        "colab_type": "text"
      },
      "source": [
        "### Prepare for TimeSliderChoropleth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kPiGySqZ0Ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import branca.colormap as cm\n",
        "# take log of import values in mil?bil? so that they are comparable between different sizes of countries' imports\n",
        "gdf_commodity1['log_value'] = np.log10(gdf_commodity1['value']+1)\n",
        "max_colour = max(gdf_commodity1['log_value'])\n",
        "min_colour = min(gdf_commodity1['log_value'])\n",
        "#cmap = cm.linear.YlOrRd_09.scale(min_colour, max_colour)\n",
        "cmap = cm.linear.Reds_09.scale(min_colour, max_colour)\n",
        "gdf_commodity1['colour'] = gdf_commodity1['log_value'].map(cmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCAUgO_pZ0oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create style_dict for the TimeSliderChoropleth (choice of color and opacity)\n",
        "country_list = gdf_commodity1['COUNTRY'].unique().tolist()\n",
        "country_idx = range(len(country_list))\n",
        "\n",
        "style_dict = {}\n",
        "for i in country_idx:\n",
        "    country = country_list[i]\n",
        "    result = gdf_commodity1[gdf_commodity1['COUNTRY'] == country]\n",
        "    # Reorder data by country and date\n",
        "    result = result.sort_values(by=['date'])\n",
        "    # Reset index\n",
        "    result.reset_index(inplace=True,drop=True)\n",
        "\n",
        "    inner_dict = {}\n",
        "    for _, r in result.iterrows():\n",
        "        inner_dict[int(r['date_sec'])] = {'color': r['colour'], 'opacity': 0.7}\n",
        "    style_dict[str(i)] = inner_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMrkDTk2Z0wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create geopandas dataframe\n",
        "countries_df = gdf_commodity1[['geometry']]\n",
        "countries_gdf = gpd.GeoDataFrame(countries_df)\n",
        "countries_gdf = countries_gdf.drop_duplicates().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ7Aw2wDG2bF",
        "colab_type": "text"
      },
      "source": [
        "### Function to select subset of data by commodity and prepare data for TimeSliderChoropleth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpcgwXZ7G12f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def timesliderchoropleth_oneshot(commodity):\n",
        "  uk_imports_commodity1 = uk_imports[uk_imports['COMMODITY'] == commodity]\n",
        "\n",
        "  # Drop unneeded columns\n",
        "  uk_imports_commodity1.drop(columns=['DIRECTION','commodity_key'],inplace=True)\n",
        "\n",
        "  # Stretch out the data\n",
        "  uk_imports_commodity1 = uk_imports_commodity1.melt(id_vars=['COMMODITY', 'COUNTRY'], var_name='date')\n",
        "\n",
        "  # Reformat date to actual datetime\n",
        "  uk_imports_commodity1['date'] = uk_imports_commodity1['date'].apply(lambda x:datetime.strptime(x.split('_')[0],'%Y%b'))\n",
        "  uk_imports_commodity1['date_sec'] = uk_imports_commodity1['date'].astype(int) / 10**9\n",
        "  uk_imports_commodity1['date_sec'] = uk_imports_commodity1['date_sec'].astype(int).astype(str)\n",
        "\n",
        "  # Reorder data by country and date\n",
        "  uk_imports_commodity1 = uk_imports_commodity1.sort_values(by=['COUNTRY','date'])\n",
        "\n",
        "  # Reset index\n",
        "  uk_imports_commodity1.reset_index(inplace=True,drop=True)\n",
        "\n",
        "  gdf_commodity1 = uk_imports_commodity1.merge(gdf_countries, left_on='COUNTRY',right_on='COUNTRY')\n",
        "\n",
        "  import branca.colormap as cm\n",
        "\n",
        "\n",
        "  gdf_commodity1.loc[gdf_commodity1['date']=='1998-01-01','value'] = 0\n",
        "  gdf_commodity1.dropna(inplace=True)\n",
        "\n",
        "  max_colour = max(gdf_commodity1['value'])\n",
        "  min_colour = min(gdf_commodity1['value'])\n",
        "  #cmap = cm.linear.YlOrRd_09.scale(min_colour, max_colour)\n",
        "  #cmap = cm.linear.Reds_09.scale(min_colour, max_colour)\n",
        "  cmap = cm.LinearColormap( colors=['red','green'], vmin=min_colour,vmax=max_colour)\n",
        "  gdf_commodity1['colour'] = gdf_commodity1['value'].map(cmap)\n",
        "\n",
        "  # Create style_dict for the TimeSliderChoropleth (choice of color and opacity)\n",
        "  country_list = gdf_commodity1['COUNTRY'].unique().tolist()\n",
        "  country_idx = range(len(country_list))\n",
        "\n",
        "  style_dict = OrderedDict()\n",
        "  for i in country_idx:\n",
        "      country = country_list[i]\n",
        "      result = gdf_commodity1[gdf_commodity1['COUNTRY'] == country]\n",
        "\n",
        "      # Reorder data by country and date\n",
        "      result = result.sort_values(by=['date'])\n",
        "      # Reset index\n",
        "      result.reset_index(inplace=True,drop=True)\n",
        "\n",
        "      inner_dict = {}\n",
        "      for _, r in result.iterrows():\n",
        "        if r['value']==0:\n",
        "          inner_dict[int(r['date_sec'])] = {'color': r['colour'], 'opacity': 0}\n",
        "        else:\n",
        "          inner_dict[int(r['date_sec'])] = {'color': r['colour'], 'opacity': 0.4}\n",
        "      style_dict[str(i)] = inner_dict\n",
        "\n",
        "  for key in style_dict.keys():\n",
        "    style_dict[key][883612800]['opacity'] = 0\n",
        "\n",
        "  # Create geopandas dataframe\n",
        "  countries_df = gdf_commodity1[['geometry']]\n",
        "  countries_gdf = gpd.GeoDataFrame(countries_df)\n",
        "  countries_gdf = countries_gdf.drop_duplicates().reset_index()\n",
        "  return countries_gdf,style_dict,cmap"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIzAjWsOh1_t",
        "colab_type": "text"
      },
      "source": [
        "# Folium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhHQvxNXfHp-",
        "colab_type": "text"
      },
      "source": [
        "### Marker popup GDP growth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O4XF7Le7W88",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d65e0841-9a2b-4907-9a23-9d6a87ac877b"
      },
      "source": [
        "# Initiate map\n",
        "m = folium.Map(min_zoom=2, max_bounds=True,tiles='cartodbpositron')\n",
        "\n",
        "# Add commodities timesliderchoropleth\n",
        "print(\"Generating commodities timesliderchoropleth for all countries...\")\n",
        "time.sleep(1)\n",
        "for i in trange(4):\n",
        "  countries_gdf,style_dict,cmap =  timesliderchoropleth_oneshot(commodities[i])\n",
        "  g = TimeSliderChoropleth(    \n",
        "      data=countries_gdf.to_json(),\n",
        "      styledict=style_dict,name='Import : ' + ' '.join(commodities[i].split()[1:]),\n",
        "      overlay=True,\n",
        "      control=True,\n",
        "      show=True).add_to(m)\n",
        "  cmap.caption = 'Import : ' + ' '.join(commodities[i].split()[1:]) + 'million pounds'\n",
        "  cmap.add_to(m)\n",
        "\n",
        "# Create markers for each country with annual gdp growth % graph\n",
        "m = folium_feature_group(mapobj=m,\n",
        "                          df=country_markers,\n",
        "                          cluster_name='Annual GDP Growth %',\n",
        "                          icon_color='black',\n",
        "                          icon_type='info-sign',\n",
        "                          show=False)\n",
        "\n",
        "folium.LayerControl().add_to(m)\n",
        "\n",
        "m.save(outfile='gdrive/My Drive/PA Consulting/DIT EU Support/DIT demo1.html')\n",
        "m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating commodities timesliderchoropleth for all countries...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnaHcF_vpfPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}